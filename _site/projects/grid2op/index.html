
<!DOCTYPE html>
<html lang="en">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="fediverse:creator" content="@dpaletti@social.coop">

<head>
    <link rel="stylesheet" href="../../../css/stylesheet.css">
    <link rel="icon" type="image/x-icon" href="../../../assets/favicon.ico">
    <link rel="stylesheet" href="../../../css/katex.min.css">
    <title>PPO algorithms on Grid2OP - Daniele Paletti</title>
</head>

<header>
    <a href="../../.." class="navbar-logo">
        <img src="../../../assets/portfolio_logo.svg">
    </a>
    <div class="navbar-links">
        <div class="navbar-item yellow"> <a class="disable-jquery-coloring navbar-link" href="../../../blog/index.html">blog</a></div>
        <div class="navbar-item blue"> <a class="disable-jquery-coloring navbar-link" href="../../../projects/index.html">projects</a></div>
        <div class="navbar-item red"> <a class="disable-jquery-coloring navbar-link" href="../../../about/index.html">about</a></div>
    </div>
</header>


<body>


<div class="blog-post-content">
    
<div class="left-aligned" style="margin-bottom: 5vh">
  <span class="page-title"> PPO algorithms on Grid2OP </span>
  <div class="under-title viewport-margin">
    <a
      href="https://github.com/dpaletti/ppo-on-grid2op"
      class="disable-jquery-coloring link blue"
      style="font-size: calc(0.6vw + 0.8vh)"
    >
      github
    </a>
  </div>
  <span class="second-level-header"> Why </span>
  <p>
    Power grid operation is an increasingly complex task due to the
    unpredictability of sustainable energy sources (wind, solar, waves...).
    Reinforcement learning algorithms can be beneficial in supporting operators
    and avoid blackouts.
  </p>
  <span class="second-level-header"> What </span>
  <p>
    I have developed several variations of a PPO (proximal policy optimization)
    algorithm on the Grid2OP platform. I re-ran the benchmarks provided by the
    L2RPN (learning to run a power network) challenge and extended them with
    different reward functions, graph-neural network based embeddings, and a
    maskable action mechanism.
  </p>
  <span class="second-level-header"> How </span>
  <p>
    I have implemented the algorithms with PyTorch, Stable-Baselines,
    PyTorch-Geometric, and the Grid2OP environment utilities. The training runs
    have been monitored with Tensorboard. Finally, I have prepared the results
    data with Polars and plotted the results with Plotly.
  </p>
</div>

</div>

<footer>
    <a href="../../.." class="footer-navbar-logo">
        <img src="../../../assets/portfolio_logo.svg">
    </a>
    <div class="navbar-links">
        <div class="footer-navbar-item red"> <a class="disable-jquery-coloring navbar-link" href="https://github.com/DPaletti">github</a></div>
        <div class="footer-navbar-item yellow"> <a class="disable-jquery-coloring navbar-link" href="https://www.linkedin.com/in/daniele-paletti/">linkedin</a></div>
        <div class="footer-navbar-item blue"> <a class="disable-jquery-coloring navbar-link" rel="me" href="https://social.coop/@dpaletti">mastodon</a></div>
        <div class="footer-navbar-item red"> <a class="disable-jquery-coloring navbar-link" href="https://codeberg.org/dpaletti">codeberg</a></div>
    </div>
</footer>


</body>
</html>